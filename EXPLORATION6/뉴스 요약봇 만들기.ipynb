{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee65e60",
   "metadata": {},
   "source": [
    "1.텍스트 요약(Text Summarization)\n",
    "\n",
    "- 텍스트 요약 방법인 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)에 대해서 알아봅니다.\n",
    "\n",
    "\n",
    "2.인공 신경망으로 텍스트 요약 훈련시키기\n",
    "\n",
    "- seq2seq 모델에 대한 개요와 구조 그리고 요소들에 대해서 알아봅니다.\n",
    "\n",
    "\n",
    "3.데이터 준비하기\n",
    "\n",
    "- Kaggle에서 제공하는 아마존 리뷰 데이터셋을 다운받고, 데이터를 확인해 봅니다.\n",
    "\n",
    "\n",
    "4 ~ 6.데이터 전처리하기\n",
    "\n",
    "- 불용어 제거, 정규화, 정수인코딩 등의 데이터 전처리 과정을 코드로 구현합니다.\n",
    "\n",
    "\n",
    "7.모델 설계하기\n",
    "\n",
    "- 인코더와 디코더, 어텐셔을 설계하고 코드로 구현합니다.\n",
    "\n",
    "\n",
    "8.모델 훈련하기\n",
    "\n",
    "- EarlyStopping에 대해서 알아보고, 이를 적용하여 모델을 학습합니다.\n",
    "\n",
    "\n",
    "9.인퍼런스 모델 구현하기\n",
    "\n",
    "- 정수 인덱스 행렬로 나온 결과값을 실제 데이터로 복원하는 인퍼런스 모델을 코드로 구현합니다.\n",
    "\n",
    "\n",
    "10.모델 테스트하기\n",
    "\n",
    "- 모델을 통해 얻은 요약문과 실제 요약문을 비교해 봅니다.\n",
    "\n",
    "\n",
    "11.추출적 요약 해보기\n",
    "\n",
    "- summa 패키지를 사용하여 추출적 요약(Extractive Summarization)을 해봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54220a72",
   "metadata": {},
   "source": [
    "# 텍스트 요약(Text Summarization)\n",
    "- 긴 길이의 문서(Document) 원문을 핵심 주제만으로 구성된 짧은 요약(Summary) 문장들로 변환하는 것\n",
    "\n",
    "- 텍스트 요약은 크게 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)의 두 가지 접근\n",
    "\n",
    "## 1. 추출적 요약(Extractive Summarization)\n",
    "\n",
    "-- 단어 그대로 원문에서 문장들을 추출해서 요약하는 방식\n",
    "\n",
    "-- 결과로 나온 문장들 간의 호응이 자연스럽지 않을 수 있다는 것\n",
    "\n",
    "-- 딥 러닝보다는 주로 전통적인 머신 러닝 방식에 속하는 텍스트 랭크(TextRank)와 같은 알고리즘을 사용해서 이 방법을 사용\n",
    "\n",
    "-- 원문을 구성하는 문장 중 어느 것이 요약문에 들어갈 핵심문장인지를 판별한다는 점에서 문장 분류(Text Classification) 문제\n",
    "\n",
    "## 2. 추상적 요약(Abstractive Summarization)\n",
    "\n",
    "-- 원문으로부터 내용이 요약된 새로운 문장을 생성해내는 것\n",
    "\n",
    "-- 새로운 문장이라는 것은 결과로 나온 문장이 원문에 원래 없던 문장일 수도 있다는 것\n",
    "\n",
    "-- 자연어 처리 분야 중 자연어 생성(Natural Language Generation, NLG)의 영역"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345cfa2",
   "metadata": {},
   "source": [
    "# 인공 신경망으로 텍스트 요약 훈련시키기\n",
    "\n",
    "- seq2seq 모델을 통해서 Abstractive summarization 방식의 텍스트 요약기를 만들어보기\n",
    "\n",
    "## seq2seq\n",
    "\n",
    "1. 원문을 첫 번째 RNN인 인코더로 입력하면, 인코더는 이를 하나의 고정된 벡터로 변환\n",
    "\n",
    "       ㄴ 이 벡터를 문맥 정보를 가지고 있는 벡터라고 하여 컨텍스트 벡터(context vector)\n",
    "\n",
    "2. 두 번째 RNN인 디코더는 이 컨텍스트 벡터를 전달받아 한 단어씩 생성해내서 요약 문장을 완성\n",
    "\n",
    "**************************************************************************************************************************************\n",
    "-- seq2seq를 구현할 때, 인코더/디코더로 바닐라 RNN이 아니라 LSTM을 사용\n",
    "\n",
    "    ㄴ LSTM이 바닐라 RNN과 다른 점은 다음 time step의 셀에 hidden state뿐만 아니라, cell state도 함께 전달한다는 점\n",
    "\n",
    "    ㄴ 인코더가 디코더에 전달하는 컨텍스트 벡터 또한 hidden state h와 cell state c 두 개의 값 모두 존재해야 한다는 뜻\n",
    "\n",
    "-- 디코더는 시작 토큰 SOS가 입력되면, 각 시점마다 단어를 생성하고 이 과정을 종료 토큰 EOS를 예측하는 순간까지 멈추지 x\n",
    "\n",
    "    ㄴ 훈련 데이터의 예측 대상 시퀀스의 앞, 뒤에는 시작 토큰과 종료 토큰을 넣어주는 전처리를 통해 어디서 멈춰야 하는지 알려줄 필요o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7052c3e",
   "metadata": {},
   "source": [
    "## 어텐션 메커니즘을 통한 새로운 컨텍스트 벡터 사용하기\n",
    "- 기존에 배운 seq2seq를 수정하고, 새로운 모듈을 붙여 모델의 성능 ↑\n",
    "\n",
    "-- 기존의 seq2seq는 인코더의 마지막 time step의 hidden state를 컨텍스트 벡터로 사용\n",
    "       \n",
    "       ㄴ 하지만 RNN 계열의 인공 신경망(바닐라 RNN, LSTM, GRU)의 한계로 인해 이 컨텍스트 정보에는 이미 입력 시퀀스의 많은 정보가 손실이 된 상태\n",
    "       \n",
    "## 어텐션 메커니즘(Attention Mechanism)\n",
    "- 인코더의 모든 step의 hidden state의 정보가 컨텍스트 벡터에 전부 반영되도록 하는 것\n",
    "\n",
    "- 하지만 인코더의 모든 hidden state가 동일한 비중으로 반영되는 것이 아니라, 디코더의 현재 time step의 예측에 인코더의 각 step이 얼마나 영향을 미치는지에 따른 가중합으로 계산되는 방식\n",
    "\n",
    "        ㄴ 여기서 주의해야 할 것은, 컨텍스트 벡터를 구성하기 위한 인코더 hidden state의 가중치 값은 디코더의 현재 스텝이 어디냐에 따라 계속 달라진다는 점\n",
    "         즉, 디코더의 현재 문장 생성 부위가 주어부인지 술어부인지 목적어인지 등에 따라 인코더가 입력 데이터를 해석한 컨텍스트 벡터가 다른 값이 된다는 것\n",
    "         \n",
    "--> 디코더의 현재 스텝에 따라 동적으로 달라지는 인코더의 컨텍스트 벡터를 사용해서 현재의 예측에 활용하면, 디코더가 좀 더 정확한 예측을 할 수 o\n",
    "\n",
    "☆ 이러한 Attention 기법은 seq2seq을 비롯하여 향후 다양한 딥러닝 분야를 획기적으로 발전시킨 핵심 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab46d10",
   "metadata": {},
   "source": [
    "## 지금까지의 내용을 정리\n",
    "\n",
    "1. seq2seq를 사용합니다.\n",
    "2. RNN 계열 중 LSTM을 사용하므로 hidden state뿐만 아니라 cell state도 사용해야 합니다.\n",
    "3. 디코더의 예측 시퀀스에는 시작 토큰 SOS와 예측 토큰 EOS를 시퀀스의 앞, 뒤로 붙입니다.\n",
    "4. seq2seq를 구동시키면 디코더는 시작 토큰을 입력받아 예측을 시작합니다.\n",
    "5. seq2seq 기본 모델과 달리, 어텐션 메커니즘을 이용해 인코더의 hidden state의 중요도를 취합한 컨텍스트 벡터를 디코더 스텝별로 계산합니다.\n",
    "6. 계산된 컨텍스트 벡터를 이용해서 디코더는 다음 등장할 단어를 예측합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5418d",
   "metadata": {},
   "source": [
    "# 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa437fb5",
   "metadata": {},
   "source": [
    "NLTK의 불용어(stopwords)를 사용\n",
    "\n",
    "NLTK 패키지에서 불용어 사전을 다운로드하고, 데이터 전처리를 위한 나머지 패키지도 함께 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcc8a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359be59",
   "metadata": {},
   "source": [
    "링크에서 다운로드 받은 데이터(Reviews.csv)는 총 568,454개의 샘플을 가짐\n",
    "\n",
    "모든 샘플을 사용하지는 않고, 간단히 10만 개의 샘플만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebbc9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d64e71",
   "metadata": {},
   "source": [
    " 이 중에 5개만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e6e8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123bb1a",
   "metadata": {},
   "source": [
    "전체 데이터 중 Summary 열과 Text 열만 훈련에 사용할 거라, 이 두 개의 열만 별도로 저장하고, 다시 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6637e21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89265</th>\n",
       "      <td>Looking for something special on your english ...</td>\n",
       "      <td>Fabulous (but pricey)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33451</th>\n",
       "      <td>I am on a low carb and sugar diet, and needles...</td>\n",
       "      <td>Welcome taste relief in my diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90772</th>\n",
       "      <td>It has a really nice flavor. I love the extra ...</td>\n",
       "      <td>Love this product!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20514</th>\n",
       "      <td>Wonderful flavors at a good price all from the...</td>\n",
       "      <td>Torani sugar free variety pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86756</th>\n",
       "      <td>I bought these sprinkles for my cupcakes and n...</td>\n",
       "      <td>These Are Great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88252</th>\n",
       "      <td>We have been using the espresso grind of Sant'...</td>\n",
       "      <td>It makes cappucinnos an exceptional experience.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51218</th>\n",
       "      <td>I purchased this to send to my daughter at uni...</td>\n",
       "      <td>Wonderful Sweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42625</th>\n",
       "      <td>I'm sure there is probably someone out there w...</td>\n",
       "      <td>Blech! This stuff tastes awful unsweetened.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51273</th>\n",
       "      <td>I live in a hot dry climate so I make a ton of...</td>\n",
       "      <td>This tea is lovely all year long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28268</th>\n",
       "      <td>This product can be used as an add in to a col...</td>\n",
       "      <td>Ojai Lemonaise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78341</th>\n",
       "      <td>I have to agree with the sizeable minority her...</td>\n",
       "      <td>overwhelmingly bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63462</th>\n",
       "      <td>I love espresso.  When I heard about this prod...</td>\n",
       "      <td>Great espresso taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27860</th>\n",
       "      <td>Although my dogs love the taste of this stuff,...</td>\n",
       "      <td>Liver Paste - pretty runny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31668</th>\n",
       "      <td>I want to start by saying I am not a professio...</td>\n",
       "      <td>My Sensitve Stomach Cats Love it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82626</th>\n",
       "      <td>For those who like hot tea freshly prepared, b...</td>\n",
       "      <td>Excellent product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "89265  Looking for something special on your english ...   \n",
       "33451  I am on a low carb and sugar diet, and needles...   \n",
       "90772  It has a really nice flavor. I love the extra ...   \n",
       "20514  Wonderful flavors at a good price all from the...   \n",
       "86756  I bought these sprinkles for my cupcakes and n...   \n",
       "88252  We have been using the espresso grind of Sant'...   \n",
       "51218  I purchased this to send to my daughter at uni...   \n",
       "42625  I'm sure there is probably someone out there w...   \n",
       "51273  I live in a hot dry climate so I make a ton of...   \n",
       "28268  This product can be used as an add in to a col...   \n",
       "78341  I have to agree with the sizeable minority her...   \n",
       "63462  I love espresso.  When I heard about this prod...   \n",
       "27860  Although my dogs love the taste of this stuff,...   \n",
       "31668  I want to start by saying I am not a professio...   \n",
       "82626  For those who like hot tea freshly prepared, b...   \n",
       "\n",
       "                                               Summary  \n",
       "89265                            Fabulous (but pricey)  \n",
       "33451                  Welcome taste relief in my diet  \n",
       "90772                               Love this product!  \n",
       "20514                   Torani sugar free variety pack  \n",
       "86756                                 These Are Great!  \n",
       "88252  It makes cappucinnos an exceptional experience.  \n",
       "51218                                 Wonderful Sweets  \n",
       "42625      Blech! This stuff tastes awful unsweetened.  \n",
       "51273                 This tea is lovely all year long  \n",
       "28268                                   Ojai Lemonaise  \n",
       "78341                            overwhelmingly bitter  \n",
       "63462                             Great espresso taste  \n",
       "27860                       Liver Paste - pretty runny  \n",
       "31668                My Sensitve Stomach Cats Love it!  \n",
       "82626                                Excellent product  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text', 'Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0a6b0",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (1) 데이터 정리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba7b1e4",
   "metadata": {},
   "source": [
    "중복 샘플과 NULL 값이 존재하는 샘플 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c29e4c",
   "metadata": {},
   "source": [
    "데이터의 중복 샘플 유무를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442895c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb40be",
   "metadata": {},
   "source": [
    "데이터프레임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96da100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f27a0b1",
   "metadata": {},
   "source": [
    "데이터프레임에 Null 값이 있는지 확인하는 방법은 .isnull().sum()을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a37d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634660b0",
   "metadata": {},
   "source": [
    "Null을 제거할 때는 dropna() 함수를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0cfb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d837fda",
   "metadata": {},
   "source": [
    "텍스트 정규화와 불용어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea3faa",
   "metadata": {},
   "source": [
    "텍스트 정규화를 위한 사전(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a33111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a62d26",
   "metadata": {},
   "source": [
    "NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f764cdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9e949b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bfd8b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3516b",
   "metadata": {},
   "source": [
    "Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "368e5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "clean_text = []\n",
    "\n",
    "for text in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(text))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "570b7a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "clean_summary = []\n",
    "\n",
    "for summary in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(summary, remove_stopwords=False))\n",
    "\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b4b96",
   "metadata": {},
   "source": [
    "보다 쉽게 확인하기 위해 데이터들을 데이터프레임에 재저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7427498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e99b64",
   "metadata": {},
   "source": [
    ".isnull().sum()을 사용해서 Null 값이 생겼는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6146d084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721c774",
   "metadata": {},
   "source": [
    "Summary 열에서 70개의 Null 값이 생김\n",
    "\n",
    "원래는 단어가 있었는데, 정제 과정에서 모든 단어가 제거되어 빈 샘플이 70개나 생겼다는 의미\n",
    "\n",
    "이 샘플들은 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee0fbbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8efd7",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (2) 훈련데이터와 테스트데이터 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eade013",
   "metadata": {},
   "source": [
    "샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b14092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcwUlEQVR4nO3dfbgWdb3v8fdHUHT7BARxIZgLj5x29qAhKl1ZWe4QH3baOWp6LNBIrtLS9q4Mtp18KK/0tI+W7VIp2aLbNE5mchRDQsjdKRVQEvBhs0Tcgg+gKKCWCX7PH/O7ZViuh2Fg7nvda31e1zXXmvnOb+b+zrplfZ2Z3/xGEYGZmVkZOzU6ATMza14uImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiVhFJr+SmNyX9Obd8eon9HSlpVRW5mpXVt9EJmPVUEbFHbV7SSuALEfHbxmVktuP5TMSsziTtJGmypCckvShphqSBad3Vkm7Ntb1c0lxJuwN3Afvkzmb2adQxmNW4iJjV31eAE4GPAfsALwE/Tuu+Brxf0hmSPgJMBCZExKvAMcAzEbFHmp6pf+pmW/PlLLP6+yLw5YhYBSDpIuA/JX0uIl6T9Dmys46NwFdq7cy6IxcRs/rbD7hN0pu52GZgCLA6Iu6XtAJ4JzCjEQmaFeXLWWb19zRwTET0z027RsRqAEnnAP2AZ4Dzc9t5yG3rdlxEzOrvGuBSSfsBSBos6YQ0/1+B7wKfBT4HnC/p4LTd88A7JO1d/5TN2uciYlZ/PwRmAndL2gjcBxwuqS/wb8DlEfGniFgO/BNwo6R+EfEYcDOwQtLL7p1l3YH8UiozMyvLZyJmZlaai4iZmZXmImJmZqW5iJiZWWm97mHDQYMGRUtLS6PTMDNrGosWLXohIga3t67XFZGWlhYWLlzY6DTMzJqGpKc6WufLWWZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlZar3tifXu0TL6zw3UrLzuujpmYmXUPPhMxM7PSKi0iklZKWiJpsaSFKTZQ0hxJy9PPASkuSVdJapX0sKRRuf1MSO2XS5qQix+S9t+atlWVx2NmZlurx5nIxyPi4IgYnZYnA3MjYiQwNy0DHAOMTNMk4GrIig5wIXA4cBhwYa3wpDZn5bYbV/3hmJlZTSMuZ50ATE/z04ETc/EbInMf0F/SUOBoYE5ErIuIl4A5wLi0bq+IuC+yF8XfkNuXmZnVQdVFJIC7JS2SNCnFhkTEs2n+OWBImh8GPJ3bdlWKdRZf1U78bSRNkrRQ0sK1a9duz/GYmVlO1b2zjoiI1ZLeCcyR9Fh+ZUSEpKg4ByJiKjAVYPTo0ZV/nplZb1HpmUhErE4/1wC3kd3TeD5diiL9XJOarwb2zW0+PMU6iw9vJ25mZnVSWRGRtLukPWvzwFhgKTATqPWwmgDcnuZnAuNTL60xwPp02Ws2MFbSgHRDfSwwO63bIGlM6pU1PrcvMzOrgyovZw0Bbku9bvsCP4+I30haAMyQNBF4CjgltZ8FHAu0Aq8BZwJExDpJ3wEWpHaXRMS6NH82cD2wG3BXmszMrE4qKyIRsQI4qJ34i8BR7cQDOKeDfU0DprUTXwi8b7uTNTOzUvzEupmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlplRcRSX0kPSTpjrQ8QtL9klol/ULSLineLy23pvUtuX1MSfHHJR2di49LsVZJk6s+FjMz21o9zkTOAx7NLV8OXBkRBwAvARNTfCLwUopfmdoh6UDgVOC9wDjgJ6kw9QF+DBwDHAicltqamVmdVFpEJA0HjgN+lpYFfAL4ZWoyHTgxzZ+Qlknrj0rtTwBuiYjXI+JJoBU4LE2tEbEiIv4K3JLamplZnVR9JvID4HzgzbT8DuDliNiUllcBw9L8MOBpgLR+fWr/VrzNNh3F30bSJEkLJS1cu3btdh6SmZnVVFZEJB0PrImIRVV9RlERMTUiRkfE6MGDBzc6HTOzHqNvhfv+MPApSccCuwJ7AT8E+kvqm842hgOrU/vVwL7AKkl9gb2BF3Pxmvw2HcXNzKwOKjsTiYgpETE8IlrIbozfExGnA/OAk1KzCcDtaX5mWiatvyciIsVPTb23RgAjgQeABcDI1Ntrl/QZM6s6HjMze7sqz0Q68k3gFknfBR4Crkvx64AbJbUC68iKAhGxTNIM4BFgE3BORGwGkPRlYDbQB5gWEcvqeiRmZr1cXYpIRMwH5qf5FWQ9q9q2+QtwcgfbXwpc2k58FjBrB6ZqZmbbwE+sm5lZaV0WEUknS9ozzX9L0q8kjao+NTMz6+6KnIn8z4jYKOkI4O/I7l1cXW1aZmbWDIoUkc3p53HA1Ii4E9ilupTMzKxZFCkiqyVdC3wGmCWpX8HtzMyshytSDE4h60Z7dES8DAwEvlFlUmZm1hy6LCIR8RqwBjgihTYBy6tMyszMmkOR3lkXkj0gOCWFdgb+rcqkzMysORS5nPVp4FPAqwAR8QywZ5VJmZlZcyhSRP6axrAKAEm7V5uSmZk1iyJFZEbqndVf0lnAb4GfVpuWmZk1gy7HzoqIf5b0SWAD8G7g2xExp/LMzMys2ys0AGMqGi4cZma2lQ6LiKSNpPsgbVcBERF7VZaVmZk1hQ6LSES4B5aZmXWq0OWsNGrvEWRnJr+PiIcqzcrMzJpCkYcNvw1MB94BDAKul/StqhMzM7Pur8iZyOnAQenNg0i6DFgMfLfCvMzMrAkUeU7kGWDX3HI/YHU16ZiZWTMpciayHlgmaQ7ZPZFPAg9IugogIs6tMD8zM+vGihSR29JUM7+aVMzMrNkUeWJ9ej0SMTOz5lOkd9bxkh6StE7SBkkbJW2oR3JmZta9Fbmc9QPgvwFL0mi+ZmZmQLHeWU8DS11AzMysrSJnIucDsyT9Dni9FoyIKyrLyszMmkKRInIp8ArZsyK7VJuOmZk1kyJFZJ+IeF/lmZiZWdMpck9klqSxlWdiZmZNp0gR+RLwG0l/dhdfMzPLK/Kwod8rYmZm7Sr6PpEBwEhyAzFGxL1VJWVmZs2hyBPrXwDuBWYDF6efFxXYbldJD0j6k6Rlki5O8RGS7pfUKukXknZJ8X5puTWtb8nta0qKPy7p6Fx8XIq1Spq8jcduZmbbqcg9kfOAQ4GnIuLjwAeBlwts9zrwiYg4CDgYGCdpDHA5cGVEHAC8BExM7ScCL6X4lakdkg4ETgXeC4wDfiKpj6Q+wI+BY4ADgdNSWzMzq5MiReQvuRdS9YuIx4B3d7VRZF5JizunKYBPAL9M8enAiWn+hLRMWn+UJKX4LRHxekQ8CbQCh6WpNSJWRMRfgVtSWzMzq5MiRWSVpP7Ar4E5km4Hniqy83TGsBhYA8wBngBejohNtX0Dw9L8MLIhVkjr15O9kveteJttOoq3l8ckSQslLVy7dm2R1M3MrIAivbM+nWYvkjQP2Bv4TZGdR8Rm4OBUhG4D/rZkntslIqYCUwFGjx7tMcDMzHaQIjfW/4ukfrVFoAX4m235kIh4GZgHfAjoL6lWvIaz5VW7q4F902f2JStWL+bjbbbpKG5mZnVS5HLWrcBmSQeQ/d/8vsDPu9pI0uB0BoKk3cheq/soWTE5KTWbANye5memZdL6e9LIwTOBU1PvrRFkXY0fABYAI1Nvr13Ibr7PLHA8Zma2gxR5TuTNiNgk6dPAjyLiR5IeKrDdUGB66kW1EzAjIu6Q9Ahwi6TvAg8B16X21wE3SmoF1pEVBSJimaQZwCPAJuCcdJkMSV8m63LcB5gWEcsKHreZme0ARYrIG5JOIztL+PsU27mrjSLiYbLuwG3jK8h6VrWN/wU4uYN9XUo2mnDb+CxgVle5mJlZNYpczjqT7F7GpRHxZLqkdGO1aZmZWTMo0jvrEeDc3PKTpAcBzcysdytyJmJmZtYuFxEzMyutwyIi6cb087z6pWNmZs2kszORQyTtA3xe0gBJA/NTvRI0M7Puq7Mb69cAc4H9gUVkT6vXRIqbmVkv1uGZSERcFRHvIXuIb/+IGJGbXEDMzKxQF98vSToI+EgK3ZseJDQzs16uyACM5wI3Ae9M002SvlJ1YmZm1v0VGfbkC8DhEfEqgKTLgT8CP6oyMTMz6/6KPCciYHNueTNb32Q3M7NeqsiZyL8C90u6LS2fyJaRd83MrBcrcmP9CknzgSNS6MyIKDIUvJmZ9XBFzkSIiAeBByvOxczMmozHzjIzs9JcRMzMrLROi4ikPpLm1SsZMzNrLp0WkfQu8zcl7V2nfMzMrIkUubH+CrBE0hzg1VowIs7teJPep2XynZ2uX3nZcXXKxMysfooUkV+lyczMbCtFnhOZLmk34F0R8XgdcjIzsyZRZADGvwcWA79JywdLmllxXmZm1gSKdPG9CDgMeBkgIhbjF1KZmRnFisgbEbG+TezNKpIxM7PmUuTG+jJJ/wPoI2kkcC7wh2rTMjOzZlDkTOQrwHuB14GbgQ3AVyvMyczMmkSR3lmvARekl1FFRGysPi0zM2sGRXpnHSppCfAw2UOHf5J0SPWpmZlZd1fknsh1wNkR8e8Ako4ge1HVB6pMzMzMur8i90Q21woIQET8HthUXUpmZtYsOiwikkZJGgX8TtK1ko6U9DFJPwHmd7VjSftKmifpEUnLJJ2X4gMlzZG0PP0ckOKSdJWkVkkPp8+u7WtCar9c0oRc/BBJS9I2V0nyu9/NzOqos8tZ/7vN8oW5+Siw703A1yLiQUl7AovSII5nAHMj4jJJk4HJwDeBY4CRaTocuBo4XNLA9Nmj0+cukjQzIl5Kbc4C7gdmAeOAuwrkZmZmO0CHRSQiPr49O46IZ4Fn0/xGSY8Cw4ATgCNTs+lkZzXfTPEbIiKA+yT1lzQ0tZ0TEesAUiEal977vldE3JfiNwAn4iJiZlY3Xd5Yl9QfGA+05Ntvy1DwklqAD5KdMQxJBQbgOWBImh8GPJ3bbFWKdRZf1U68vc+fBEwCeNe73lU0bTMz60KR3lmzgPuAJZQY7kTSHsCtwFcjYkP+tkVEhKQil8a2S0RMBaYCjB49uvLPMzPrLYoUkV0j4h/L7FzSzmQF5KaIqL2T5HlJQyPi2XS5ak2Krwb2zW0+PMVWs+XyVy0+P8WHt9PezMzqpEgX3xslnSVpaOpZNTDd7O5U6il1HfBoRFyRWzUTqPWwmgDcnouPT720xgDr02Wv2cBYSQNST66xwOy0boOkMemzxuf2ZWZmdVDkTOSvwPeBC9jSKyvoejj4DwOfI3vKfXGK/RNwGTBD0kTgKeCUtG4WcCzQCrwGnAkQEeskfQdYkNpdUrvJDpwNXA/sRnZD3TfVzczqqEgR+RpwQES8sC07Tg8ldvTcxlHttA/gnA72NQ2Y1k58IfC+bcnLzMx2nCKXs2pnBmZmZlspcibyKrBY0jyy4eCBbevia2ZmPVORIvLrNJmZmW2lyPtEptcjETMzaz5Fnlh/knbGyoqIrnpnmZlZD1fkctbo3PyuwMlAl8+JmJlZz9dl76yIeDE3rY6IHwDHVZ+amZl1d0UuZ43KLe5EdmZS5AzGzMx6uCLFIP9ekU3ASrY8ZW5mZr1Ykd5Z2/VeETMz67mKXM7qB/x33v4+kUuqS8vMzJpBkctZtwPrgUXknlg3MzMrUkSGR8S4yjMxM7OmU2QAxj9Ien/lmZiZWdMpciZyBHBGenL9dbLh3SMiPlBpZmZm1u0VKSLHVJ6FmZk1pSJdfJ+qRyJmZtZ8itwTMTMza5eLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZlVZZEZE0TdIaSUtzsYGS5khann4OSHFJukpSq6SHJY3KbTMhtV8uaUIufoikJWmbqySpqmMxM7P2VXkmcj3Q9t3sk4G5ETESmJuWIXvx1cg0TQKuhqzoABcChwOHARfWCk9qc1ZuO78H3sysziorIhFxL7CuTfgEYHqanw6cmIvfEJn7gP6ShgJHA3MiYl1EvATMAcaldXtFxH0REcANuX2ZmVmd1PueyJCIeDbNPwcMSfPDgKdz7ValWGfxVe3E2yVpkqSFkhauXbt2+47AzMze0rAb6+kMIur0WVMjYnREjB48eHA9PtLMrFeodxF5Pl2KIv1ck+KrgX1z7YanWGfx4e3EzcysjupdRGYCtR5WE4Dbc/HxqZfWGGB9uuw1GxgraUC6oT4WmJ3WbZA0JvXKGp/bl5mZ1UnfqnYs6WbgSGCQpFVkvawuA2ZImgg8BZySms8CjgVagdeAMwEiYp2k7wALUrtLIqJ2s/5ssh5guwF3pcnMzOqosiISEad1sOqodtoGcE4H+5kGTGsnvhB43/bkaGZm28dPrJuZWWkuImZmVpqLiJmZleYiYmZmpVV2Y9221jL5zk7Xr7zsuDplYma24/hMxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PS/HrcbqKz1+f61blm1l35TMTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0tzFtwl01v0X3AXYzBrHZyJmZlZa05+JSBoH/BDoA/wsIi5rcEp15wcVzaxRmrqISOoD/Bj4JLAKWCBpZkQ80tjMug9fCjOzKjV1EQEOA1ojYgWApFuAEwAXkYK6KjKdcQEys2YvIsOAp3PLq4DD2zaSNAmYlBZfkfR4ic8aBLxQYrvuZocdhy7fEXsppSd8Fz3hGKBnHEdPOAao9jj262hFsxeRQiJiKjB1e/YhaWFEjN5BKTVMTzgOH0P30ROOoyccAzTuOJq9d9ZqYN/c8vAUMzOzOmj2IrIAGClphKRdgFOBmQ3Oycys12jqy1kRsUnSl4HZZF18p0XEsoo+brsuh3UjPeE4fAzdR084jp5wDNCg41BENOJzzcysB2j2y1lmZtZALiJmZlaai0gBksZJelxSq6TJjc6nI5L2lTRP0iOSlkk6L8UHSpojaXn6OSDFJemqdFwPSxrV2CPYQlIfSQ9JuiMtj5B0f8r1F6kjBZL6peXWtL6loYnnSOov6ZeSHpP0qKQPNdt3Iekf0n9LSyXdLGnXZvguJE2TtEbS0lxsm3/3kiak9sslTegGx/D99N/Tw5Juk9Q/t25KOobHJR2di1f79ysiPHUykd2wfwLYH9gF+BNwYKPz6iDXocCoNL8n8B/AgcD/Aian+GTg8jR/LHAXIGAMcH+jjyF3LP8I/By4Iy3PAE5N89cAX0rzZwPXpPlTgV80OvfcMUwHvpDmdwH6N9N3QfYw75PAbrnv4Ixm+C6AjwKjgKW52Db97oGBwIr0c0CaH9DgYxgL9E3zl+eO4cD0t6kfMCL9zepTj79fDf2PtBkm4EPA7NzyFGBKo/MqmPvtZOOKPQ4MTbGhwONp/lrgtFz7t9o1OO/hwFzgE8Ad6R/3C7l/PG99J2Q98z6U5vumduoGx7B3+gOsNvGm+S7YMiLEwPS7vQM4ulm+C6ClzR/gbfrdA6cB1+biW7VrxDG0Wfdp4KY0v9Xfpdp3UY+/X76c1bX2hlYZ1qBcCkuXEj4I3A8MiYhn06rngCFpvrse2w+A84E30/I7gJcjYlNazuf51jGk9etT+0YbAawF/jVdlvuZpN1pou8iIlYD/wz8J/As2e92Ec33XdRs6+++230nbXye7AwKGngMLiI9kKQ9gFuBr0bEhvy6yP53pNv265Z0PLAmIhY1Opft1JfsUsTVEfFB4FWySyhvaYLvYgDZgKYjgH2A3YFxDU1qB+nuv/uuSLoA2ATc1OhcXES61lRDq0jamayA3BQRv0rh5yUNTeuHAmtSvDse24eBT0laCdxCdknrh0B/SbWHY/N5vnUMaf3ewIv1TLgDq4BVEXF/Wv4lWVFppu/i74AnI2JtRLwB/Irs+2m276JmW3/33fE7QdIZwPHA6akYQgOPwUWka00ztIokAdcBj0bEFblVM4Faz5IJZPdKavHxqXfKGGB97nS/ISJiSkQMj4gWst/1PRFxOjAPOCk1a3sMtWM7KbVv+P9hRsRzwNOS3p1CR5G9oqBpvguyy1hjJP1N+m+rdgxN9V3kbOvvfjYwVtKAdFY2NsUaRtlL+M4HPhURr+VWzQROTT3kRgAjgQeox9+vet4kataJrPfGf5D1crig0fl0kucRZKfoDwOL03Qs2XXpucBy4LfAwNReZC/1egJYAoxu9DG0OZ4j2dI7a//0j6IV+D9AvxTfNS23pvX7NzrvXP4HAwvT9/Frsh4+TfVdABcDjwFLgRvJev90++8CuJnsPs4bZGeFE8v87snuO7Sm6cxucAytZPc4av++r8m1vyAdw+PAMbl4pX+/POyJmZmV5stZZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4j1WJJeqWCfB0s6Nrd8kaSvb8f+Tk4j/M7bMRmWzmOlpEGNzMGak4uI2bY5mKzf/Y4yETgrIj6+A/dpVjcuItYrSPqGpAXpPQwXp1hLOgv4aXpnxt2SdkvrDk1tF6d3OCxNT/xeAnwmxT+Tdn+gpPmSVkg6t4PPP03SkrSfy1Ps22QPiF4n6ftt2g+VdG/6nKWSPpLiV0tamPK9ONd+paTvpfYLJY2SNFvSE5K+mNocmfZ5Z3q/xDWS3vY3QNJnJT2Q9nWtsne79JF0fcpliaR/2M6vxHqKRj8R68lTVRPwSvo5FphK9mTyTmRDmn+UbJjtTcDBqd0M4LNpfilbhjW/jDQcN9n7NP4l9xkXAX8ge5J7ENlYUTu3yWMfsiFEBpMNzHgPcGJaN592nk4HvkZ6upjsnRB7pvmBudh84ANpeSVb3utxJdlT8numz3w+xY8E/kL2xHkfYA5wUm77QcB7gP9bOwbgJ8B44BBgTi6//o3+fj11j8lnItYbjE3TQ8CDwN+SjS0E2QCDi9P8IqBF2dvi9oyIP6b4z7vY/50R8XpEvEA2qN+QNusPBeZHNpBhbeTVj3axzwXAmZIuAt4fERtT/BRJD6ZjeS/Zy4hqamMiLSF7sdLGiFgLvK4tb8B7ICJWRMRmsmE1jmjzuUeRFYwFkhan5f3JXsi0v6QfpfGbNmBG9n9FZj2dgO9FxLVbBbN3rryeC20Gdiux/7b72O5/VxFxr6SPAscB10u6Avh34OvAoRHxkqTrycarapvHm21yejOXU9txjtouC5geEVPa5iTpILKXUn0ROIVsXCnr5XwmYr3BbODzyt6zgqRhkt7ZUeOIeBnYKOnwFDo1t3oj2WWibfEA8DFJgyT1IXtj3u8620DSfmSXoX4K/IxsGPm9yN5Lsl7SEOCYbcwD4LA0outOwGeA37dZPxc4qfb7UfZe8v1Sz62dIuJW4FspHzOfiVjPFxF3S3oP8MdsRHNeAT5LdtbQkYnATyW9SfYHf32KzwMmp0s93yv4+c9Kmpy2Fdnlr9u72OxI4BuS3kj5jo+IJyU9RDaq7tPA/yvy+W0sAP4FOCDlc1ubXB+R9C3g7lRo3gDOAf5M9pbG2v94vu1MxXonj+Jr1g5Je0TEK2l+Mtm7uc9rcFrbRdKRwNcj4vgGp2I9iM9EzNp3nKQpZP9GniLrlWVmbfhMxMzMSvONdTMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMr7f8Do1dsKbWvtPIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e344f6",
   "metadata": {},
   "source": [
    "Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "667a9d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276c6c8",
   "metadata": {},
   "source": [
    "각각 50과 8로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하는 편이 객관적으로 길이를 결정하는 데 도움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f4b1302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b473a6b8",
   "metadata": {},
   "source": [
    "이렇게 만든 함수를 Text와 Summary에 적용해 우리가 결정한 임의의 길이가 몇%의 샘플까지 포함하는지 볼 수 o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aba8b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "506583ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b248618",
   "metadata": {},
   "source": [
    "시작 토큰과 종료 토큰 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19218294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a683c",
   "metadata": {},
   "source": [
    "인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "122f14df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d8495",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터를 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f64d469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29363 52979 54922 ...  4832  3150 53231]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a742fcd",
   "metadata": {},
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주면 잘 섞인 샘플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2487846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d17d1",
   "metadata": {},
   "source": [
    "이제 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2a54303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5080d1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d11bc",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (3) 정수 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08f2e1",
   "metadata": {},
   "source": [
    "단어 집합(vocabulary) 만들기 및 정수 인코딩 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c2bdd",
   "metadata": {},
   "source": [
    "이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어 주어야함\n",
    "\n",
    "각 단어에 고유한 정수를 맵핑하는 작업이 필요\n",
    "\n",
    "->  이 과정을 단어 집합(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c170a",
   "metadata": {},
   "source": [
    "Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee2d7a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e833a73b",
   "metadata": {},
   "source": [
    "이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, 빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행\n",
    "\n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83c5531f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 32008\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23774\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8234\n",
      "단어 집합에서 희귀 단어의 비율: 74.27518120469882\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.385659890775503\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a11567",
   "metadata": {},
   "source": [
    "등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거\n",
    "\n",
    "위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b35d1073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d814571",
   "metadata": {},
   "source": [
    "texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71e78fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[407, 1062, 1401, 1213, 23, 2, 7648, 121, 7, 16, 1436, 195, 1704, 463, 1670, 9, 120, 91, 4, 3, 1010, 928, 88, 1369], [4805, 82, 47, 8, 1, 4652, 162, 757, 330, 341, 4805, 5912, 142, 1153, 16, 18, 99, 142, 20, 26, 2045, 1196, 7, 2185, 55, 134, 20, 23, 2045, 43, 1437, 1034, 57, 23, 4805, 43, 28, 8, 12, 16, 4653], [152, 125, 113, 29, 5913, 6780, 1027, 340, 95, 212, 6, 5913, 6780, 1485, 456, 730, 16, 17, 1485, 730, 111, 2148, 2006, 401, 1438, 114, 141, 14]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bffcbf",
   "metadata": {},
   "source": [
    "이제 더 이상 텍스트 데이터가 아니라 정수가 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78b49a",
   "metadata": {},
   "source": [
    "Summary 데이터에 대해서도 동일한 작업을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "095c04a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0de03ac",
   "metadata": {},
   "source": [
    "tar_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻어서, 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bdd63a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10527\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8142\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2385\n",
      "단어 집합에서 희귀 단어의 비율: 77.34397264177828\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.892913263790528\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e564bdb",
   "metadata": {},
   "source": [
    "아까 했던 것과 동일하게 이 단어들은 모두 제거할게요. 어림잡아 2,000을 단어 집합의 크기로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e2e65bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 45, 31, 834], [1, 75], [1, 9, 5, 16, 18, 6, 5, 30], [1, 190, 42, 3], [1, 6, 586]]\n",
      "target\n",
      "decoder  [[45, 31, 834, 2], [75, 2], [9, 5, 16, 18, 6, 5, 30, 2], [190, 42, 3, 2], [6, 586, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191964be",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장\n",
    "\n",
    "이 샘플들은 모두 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df2a69d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1255\n",
      "삭제할 테스트 데이터의 개수 : 345\n",
      "훈련 데이터의 개수 : 51400\n",
      "훈련 레이블의 개수 : 51400\n",
      "테스트 데이터의 개수 : 12818\n",
      "테스트 레이블의 개수 : 12818\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470d7dcc",
   "metadata": {},
   "source": [
    "패딩하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc0559b",
   "metadata": {},
   "source": [
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업하기\n",
    "\n",
    "최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2c4ccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66291231",
   "metadata": {},
   "source": [
    "## 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cc5e264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#함수형 API\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26c355",
   "metadata": {},
   "source": [
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높임\n",
    "\n",
    "또한 LSTM은 dropout 뿐 아니라 recurrent dropout까지 사용o\n",
    "\n",
    "일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 모델의 과적합(overfitting)을 해결해주는 방법\n",
    "\n",
    "반면 recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식\n",
    "\n",
    "    ㄴ recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2afc8",
   "metadata": {},
   "source": [
    "디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8a171da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c7584",
   "metadata": {},
   "source": [
    "디코더의 출력층을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c980a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4550ae5",
   "metadata": {},
   "source": [
    "지금까지 설계한 것은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375aea0",
   "metadata": {},
   "source": [
    "그런데 디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법o\n",
    "\n",
    "--> 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93dc11b",
   "metadata": {},
   "source": [
    "어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e25b1",
   "metadata": {},
   "source": [
    "ㄴ 여기서는 TensorFlow에 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3cc6849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,145,360\n",
      "Trainable params: 4,145,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1eacb5",
   "metadata": {},
   "source": [
    "## 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69122e33",
   "metadata": {},
   "source": [
    "설계한 모델을 가지고 훈련을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d1a2e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 156s 667ms/step - loss: 2.7079 - val_loss: 2.4181\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 132s 656ms/step - loss: 2.3832 - val_loss: 2.2751\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 132s 656ms/step - loss: 2.2291 - val_loss: 2.1569\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 133s 660ms/step - loss: 2.1087 - val_loss: 2.0613\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 131s 653ms/step - loss: 2.0257 - val_loss: 2.0056\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 133s 659ms/step - loss: 1.9621 - val_loss: 1.9662\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 131s 654ms/step - loss: 1.9109 - val_loss: 1.9384\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 132s 655ms/step - loss: 1.8670 - val_loss: 1.9133\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 132s 655ms/step - loss: 1.8295 - val_loss: 1.9020\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 131s 652ms/step - loss: 1.7954 - val_loss: 1.8835\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 132s 655ms/step - loss: 1.7641 - val_loss: 1.8726\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 131s 652ms/step - loss: 1.7332 - val_loss: 1.8685\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 131s 652ms/step - loss: 1.7058 - val_loss: 1.8597\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 131s 652ms/step - loss: 1.6804 - val_loss: 1.8529\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 131s 654ms/step - loss: 1.6564 - val_loss: 1.8492\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 132s 654ms/step - loss: 1.6311 - val_loss: 1.8554\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 132s 659ms/step - loss: 1.6096 - val_loss: 1.8474\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 131s 653ms/step - loss: 1.5867 - val_loss: 1.8497\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 131s 651ms/step - loss: 1.5664 - val_loss: 1.8467\n",
      "Epoch 20/50\n",
      "201/201 [==============================] - 131s 654ms/step - loss: 1.5453 - val_loss: 1.8483\n",
      "Epoch 21/50\n",
      "201/201 [==============================] - 131s 654ms/step - loss: 1.5274 - val_loss: 1.8490\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68666472",
   "metadata": {},
   "source": [
    "'조기 종료'를 뜻하는 EarlyStopping은 특정 조건이 충족되면 훈련을 멈추는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e1ec9",
   "metadata": {},
   "source": [
    "훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정을 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb50ac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978afe8",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453949c6",
   "metadata": {},
   "source": [
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5624182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a782a22",
   "metadata": {},
   "source": [
    "seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 한다는 것\n",
    "\n",
    "ㄴ 훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한 번에 비교할 수 있으므로, 인코더와 디코더를 엮은 통짜 모델 하나만 준비\n",
    "\n",
    "ㄴ 그러나 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야함\n",
    "\n",
    "-->  이때는 인코더 모델과 디코더 모델을 분리해서 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3556fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdb380",
   "metadata": {},
   "source": [
    "어텐션 메커니즘을 사용하는 출력층을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "232436e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b6205",
   "metadata": {},
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "478a73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01589bc7",
   "metadata": {},
   "source": [
    "## 모델 테스트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d722d4",
   "metadata": {},
   "source": [
    "정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82782153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2headlines(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540ab6c",
   "metadata": {},
   "source": [
    "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1be2d70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : potent dont know dont make larger version concentration sweetness takes twice many drops big bottle dispenser better design tiny bottles sweetens nicely admit slight aftertaste think less noticeable fun use flavored unsweetened sparkling water lot easier cleaner splenda powdered form stuff great \n",
      "실제 요약 : better than the larger version \n",
      "예측 요약 :  good for me\n",
      "\n",
      "\n",
      "원문 : drinking tea since years old far one favorite herbal tea great flavor great scents brewing natural caffine free product \n",
      "실제 요약 : love it \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : cats loved treats think really help hairballs noticed changes prove treats help hairballs issues going buy treats cats finish \n",
      "실제 요약 : my cats love \n",
      "예측 요약 :  my cats love these\n",
      "\n",
      "\n",
      "원문 : product quite delicious unusual find something tastes good unhealthy great snack food \n",
      "실제 요약 : american gourmet booty \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : tea good like fact need sugar great local restaurants versions good home solution \n",
      "실제 요약 : spice tea \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : bought brand costco start constantly running received six pack version tad brand love fresh udon stick brand subscribed \n",
      "실제 요약 : almost like the other brand \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : big fan flavored coffee bought wife nice coffee base flavor vanilla overwhelming cloying \n",
      "실제 요약 : nice balance \n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : simply best chai ever used buy stores became unavailable reached amazon purchased small cans became unavailable switched bags please please please amazon stop carrying item creamy warm right spices \n",
      "실제 요약 : best chai ever \n",
      "예측 요약 :  not the best\n",
      "\n",
      "\n",
      "원문 : since drink lot milk best way keep hand cooking particular product excellent taste also economical keep hand instead toss milk liquid form need also comes easy use package \n",
      "실제 요약 : great product \n",
      "예측 요약 :  great stuff\n",
      "\n",
      "\n",
      "원문 : sea salt caramels good cannot eat one perfect dessert satisfying overly sweet eaten something similar europe unable find grateful could get amazon \n",
      "실제 요약 : amazon addictive treats \n",
      "예측 요약 :  great flavor\n",
      "\n",
      "\n",
      "원문 : sure would call meal go tuna salad like size fancy feast get ritz sized crackers get wrong tuna salad excellent creamy compared pouch style make stuff carrots nice touch minimal packaging ready eat shelf stable wish carried vending machine work \n",
      "실제 요약 : tasty snack \n",
      "예측 요약 :  my kids love it\n",
      "\n",
      "\n",
      "원문 : sauce tasty husband loves slightly spicy creamy delicious \n",
      "실제 요약 : yay taco bell \n",
      "예측 요약 :  great sauce\n",
      "\n",
      "\n",
      "원문 : discovered local trader joe stopped carrying located original colors make tasty vegetable broth carrot onion flavors strong \n",
      "실제 요약 : good taste \n",
      "예측 요약 :  just like the real thing\n",
      "\n",
      "\n",
      "원문 : love cookies love erin result cookies make smile texture makes eyes smell reminds beautiful spring days awesome would spend erin bring fresh cookies oven us enjoying together outdoor swing birds enjoying creek passed backyard thing kind kind differ much taste taste taste heaven \n",
      "실제 요약 : you \n",
      "예측 요약 :  great cookies\n",
      "\n",
      "\n",
      "원문 : spanish paprika beautiful red color paprika flavor spanish version pronounced smoky flavor going interesting find new ways use \n",
      "실제 요약 : smoky and \n",
      "예측 요약 :  good product\n",
      "\n",
      "\n",
      "원문 : birthday gift friend confirmed delicious kept plaque last \n",
      "실제 요약 : best birthday gift loved by as well \n",
      "예측 요약 :  great gift\n",
      "\n",
      "\n",
      "원문 : ordered party place treasure chest party favor box worked perfectly exactly expected would ring pops kids loved ps know people concerned breakage shipping mine arrived unbroken \n",
      "실제 요약 : yum \n",
      "예측 요약 :  great gift\n",
      "\n",
      "\n",
      "원문 : cannot say ate personally year old mother thrilled get cannot find stores anymore thought made always way goes find something really love stop making thank amazon helping make old lady happy \n",
      "실제 요약 : at last \n",
      "예측 요약 :  love these\n",
      "\n",
      "\n",
      "원문 : coconut milk light bought case light coconut milk \n",
      "실제 요약 : not light \n",
      "예측 요약 :  good for\n",
      "\n",
      "\n",
      "원문 : syrup top quality great price well went much lower price shame would like buying regularly well great syrup none less \n",
      "실제 요약 : great flavor \n",
      "예측 요약 :  great syrup\n",
      "\n",
      "\n",
      "원문 : delicious ate whole thing days share anything suggestions venison jerky package scrumptious \n",
      "실제 요약 : delicious beef \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : coffee rich smooth especially love price subscribe save wonderful automatically ships every months \n",
      "실제 요약 : love this coffee \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : absolutely love salt pepper pistachios costco sells love cashews looking forward trying unfortunately cashews heavily seasoned got heartburn hardly ever get heartburn opinion mouth almost burns pepper much idea salt pepper cashew good one would take plain roasted salted cashew day delicious taste cashew ruined seasoning \n",
      "실제 요약 : too much salt pepper \n",
      "예측 요약 :  too salty\n",
      "\n",
      "\n",
      "원문 : fool italian husband fool anyone think consistency close wheat pasta cannot wait try laws \n",
      "실제 요약 : this rice pasta is \n",
      "예측 요약 :  yummy\n",
      "\n",
      "\n",
      "원문 : greatest things world prices amazon cannot loose definatly good buy \n",
      "실제 요약 : awesome \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : sure review coffee everyone favorites happen love kona getting harder find came fast good condition complaints \n",
      "실제 요약 : kona \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : perfect summer iced tea cannot wait winter try hot mixes well black tea want little caffeine lovely fruity flavor \n",
      "실제 요약 : delicious \n",
      "예측 요약 :  best tea ever\n",
      "\n",
      "\n",
      "원문 : okay finicky wasted lots money rawhide chews finally found one thank \n",
      "실제 요약 : only rawhide my dog will chew \n",
      "예측 요약 :  not what expected\n",
      "\n",
      "\n",
      "원문 : twizzlers brand licorice much better well known brand get package free good deal black cherry good taste strawberry taste delicate barely \n",
      "실제 요약 : good licorice \n",
      "예측 요약 :  not the best\n",
      "\n",
      "\n",
      "원문 : surprised flavor bars seemed bit small first found pretty filling popular family box empty almost soon opened calories ok would expect even though fan coconut find bothersome tasted chocolate anything else cannot complain would definitely buy though might hide next time \n",
      "실제 요약 : gone in day tasty gluten free snack bar \n",
      "예측 요약 :  not as good as other brands\n",
      "\n",
      "\n",
      "원문 : little one loves yogurt blends snacks sweet creamy much healthier compared many snacks since real fruit whole milk yogurt aid digestion etc also requires refrigeration makes handy take along keep diaper bag \n",
      "실제 요약 : so yummy and convenient \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : love smart fries hard find make great snack calories bag really satisfy craving something salty crunchy without fat calories \n",
      "실제 요약 : love \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : stumbled sugar lot found replace white sugar especially brown sugar many recipes almost always better outcome much richer taste texture sense might bit sweeter regular sugar much expensive scale back bit noticed negative impact really recommend product \n",
      "실제 요약 : secret ingredient for everything \n",
      "예측 요약 :  good substitute for sugar\n",
      "\n",
      "\n",
      "원문 : cook house wife loves spice cooks many middle eastern european foods \n",
      "실제 요약 : excellent product \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : drinking cups wonderful spicy tea last months absolutely live without however last batch received almost undrinkable missing ingredient tea bitter sweet spicy would love return start sure \n",
      "실제 요약 : disappointing batch \n",
      "예측 요약 :  not as good as the original\n",
      "\n",
      "\n",
      "원문 : health conscious household trying time decrease sodium intake recently bought bouillon incredibly happy results made many pots homemade soup love broth tastes received pack noted expires approximately years purchase slightly worried enough time use bouillon give stars wish could order bouillon amazon prime smaller quantities \n",
      "실제 요약 : delicious \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : tasty already ordered second case good hurry amazon add item subscribe save program thanks advance \n",
      "실제 요약 : kitchen golden soup \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : handy add veggies make soup nice size chunks drain liquid make chicken salad even give salad topping keeps long time always \n",
      "실제 요약 : chicken quick soup \n",
      "예측 요약 :  great for quick\n",
      "\n",
      "\n",
      "원문 : like drink amazon price higher local supermarket like got individual pack \n",
      "실제 요약 : nice drink \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : sweetleaf flavored products people want something really sweet whiff flavor looking product half sweetness half flavor urge save money look another solution \n",
      "실제 요약 : dark chocolate not on your life \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : great take office especially days cannot get away convenient perfect portion size full feeling tasty good texture \n",
      "실제 요약 : quick and tasty lunch \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : prepared hot ml water like package suggests strong tasting added water sweet good flavor dissolve well problems really enjoy ginger product \n",
      "실제 요약 : too sweet \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  nice flavor\n",
      "\n",
      "\n",
      "원문 : gave bag try resulted entire family fighting youngest son wheat allergy able enjoy berries tasted much better dried berries normally would get box cereal little bars chocolate also nice touch definitely good want downside like granola bottom half bag crumbles still good though \n",
      "실제 요약 : oh man it is tasty \n",
      "예측 요약 :  good for you\n",
      "\n",
      "\n",
      "원문 : purchased grandsons try one delicious texture like soft textured oatmeal cookie loved taste fruit sweet almost like homemade preserves size right child snack whole grains fiber healthy addition anyone diet ps kids loved \n",
      "실제 요약 : like healthy cookie \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : although would prefer fancy feast eat would like break foods meow give \n",
      "실제 요약 : with eaters \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : love strawberry kiwi flavored crystal light think best flavor none others come even close good sad longer making product \n",
      "실제 요약 : strawberry kiwi crystal light is great flavor \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : ordered pack peppercorn super saver shipping got peppercorn kinda hard screw pleased peppercorn put gets ground smaller pepper genius \n",
      "실제 요약 : kinda hard to up \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : thing like hate love cannot live without much english thing language even adopted trade name amazon done world favor making weird wonderful stuff available affordable price last time looked jar british stores county costs england amazon supplier quick efficient enough last end year good job amazon \n",
      "실제 요약 : an acquired taste \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : bought tea based upon research done ingredients reading reviews posted tea wonderful flavor smell enjoyed much helps bedtime sinus issues great stuff \n",
      "실제 요약 : wonderful \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : dogs love treats chews keep dogs teeth cleaned love know get home work every night get treat excited highly recommend plus much cheaper amazon com local petsmart petco \n",
      "실제 요약 : my dogs love these \n",
      "예측 요약 :  my dogs love these\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2headlines(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e939868",
   "metadata": {},
   "source": [
    "# 추출적 요약 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eaae17",
   "metadata": {},
   "source": [
    "Summa의 summarize 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994fda7e",
   "metadata": {},
   "source": [
    "데이터 다운로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb4081b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6b8b8",
   "metadata": {},
   "source": [
    "매트릭스 시놉시스를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a95cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6b420",
   "metadata": {},
   "source": [
    "text에는 매트릭스 시놉시스가 문자열로 저장\n",
    "\n",
    "출력 결과가 아주 길기 때문에 일부만 출력해보고, 잘 저장이 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddcaa60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ec8bc",
   "metadata": {},
   "source": [
    "summarize 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65b16771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fbcb1",
   "metadata": {},
   "source": [
    "만약 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9b0b025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea46536",
   "metadata": {},
   "source": [
    "단어의 수로 요약문의 크기를 조절할 수 o\n",
    "\n",
    "단어를 50개만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad2017fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
