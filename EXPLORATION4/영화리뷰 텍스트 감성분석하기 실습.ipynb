{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6925d03d",
   "metadata": {},
   "source": [
    "아래와 같이 단 3개의 짧은 문장으로 이루어진 텍스트 데이터를 처리하는 간단한 예제를 생각해 보겠습니다.\n",
    "\n",
    "i feel hungry\n",
    "\n",
    "i eat lunch\n",
    "\n",
    "now i feel happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75370e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5eda9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1083d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f7c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2dfc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239d6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07df0b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3129324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51231754",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37/2733197300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6aca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a882c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.02229995 -0.00533615  0.0351535   0.04354313]\n",
      "  [ 0.00935321 -0.00758994 -0.04154591 -0.03961979]\n",
      "  [ 0.02615066 -0.0495734   0.01971629 -0.02734532]\n",
      "  [ 0.01842281  0.02702748 -0.01341064  0.01808132]\n",
      "  [-0.04052498  0.0381234   0.01723213  0.02004745]]\n",
      "\n",
      " [[ 0.02229995 -0.00533615  0.0351535   0.04354313]\n",
      "  [ 0.00935321 -0.00758994 -0.04154591 -0.03961979]\n",
      "  [-0.01881964  0.02662537 -0.00340669  0.0277889 ]\n",
      "  [-0.03697907  0.02783738  0.00557547  0.04503724]\n",
      "  [-0.04052498  0.0381234   0.01723213  0.02004745]]\n",
      "\n",
      " [[ 0.02229995 -0.00533615  0.0351535   0.04354313]\n",
      "  [-0.01122137 -0.00455829 -0.04835927  0.04546395]\n",
      "  [ 0.00935321 -0.00758994 -0.04154591 -0.03961979]\n",
      "  [ 0.02615066 -0.0495734   0.01971629 -0.02734532]\n",
      "  [ 0.02638106 -0.02281315 -0.00263051 -0.0361344 ]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93357f1",
   "metadata": {},
   "source": [
    "RNN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59b540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e6657",
   "metadata": {},
   "source": [
    "1-D Convolution Neural Network(1-D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0bb2b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcfdf32",
   "metadata": {},
   "source": [
    "GlobalMaxPooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5e8c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d886724",
   "metadata": {},
   "source": [
    "IMDB 영화리뷰 감성분석 (1) IMDB 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aabb9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bedca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ea6b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5eb2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64a3eebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cffd4340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54ff9eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c4be678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712544f",
   "metadata": {},
   "source": [
    "IMDB 영화리뷰 감성분석 (2) 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7accafe1",
   "metadata": {},
   "source": [
    "1. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a9aef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 163,761\n",
      "Trainable params: 163,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed2c492e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0ff73c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 4s 30ms/step - loss: 0.6930 - accuracy: 0.5119 - val_loss: 0.6925 - val_accuracy: 0.5218\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6895 - accuracy: 0.6259 - val_loss: 0.6884 - val_accuracy: 0.6589\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6701 - accuracy: 0.7761 - val_loss: 0.6382 - val_accuracy: 0.7533\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.5297 - accuracy: 0.8241 - val_loss: 0.4171 - val_accuracy: 0.8292\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.3057 - accuracy: 0.8807 - val_loss: 0.3360 - val_accuracy: 0.8590\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2032 - accuracy: 0.9249 - val_loss: 0.3358 - val_accuracy: 0.8642\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1477 - accuracy: 0.9506 - val_loss: 0.3542 - val_accuracy: 0.8585\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1090 - accuracy: 0.9677 - val_loss: 0.3967 - val_accuracy: 0.8554\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0802 - accuracy: 0.9793 - val_loss: 0.4214 - val_accuracy: 0.8532\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0571 - accuracy: 0.9885 - val_loss: 0.4706 - val_accuracy: 0.8518\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0419 - accuracy: 0.9935 - val_loss: 0.4973 - val_accuracy: 0.8494\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0317 - accuracy: 0.9957 - val_loss: 0.5414 - val_accuracy: 0.8480\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.5686 - val_accuracy: 0.8463\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0187 - accuracy: 0.9980 - val_loss: 0.6079 - val_accuracy: 0.8461\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9984 - val_loss: 0.6356 - val_accuracy: 0.8455\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.6574 - val_accuracy: 0.8450\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0107 - accuracy: 0.9989 - val_loss: 0.6887 - val_accuracy: 0.8442\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.7052 - val_accuracy: 0.8427\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.7229 - val_accuracy: 0.8434\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.7543 - val_accuracy: 0.8430\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c15b3a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.8411 - accuracy: 0.8230\n",
      "[0.8410955667495728, 0.8230400085449219]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "605e7fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a00baacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "939be26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6795a74e",
   "metadata": {},
   "source": [
    "IMDB 영화리뷰 감성분석 (3) Word2Vec의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "048249be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b57f94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d09aa97",
   "metadata": {},
   "source": [
    "gensim에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f82fa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05495201,  0.02619119,  0.0092755 ,  0.04577821,  0.02521197,\n",
       "        0.03698339, -0.02865711, -0.01176057,  0.0049194 , -0.03362763,\n",
       "        0.05326289, -0.06047808, -0.00605999,  0.01215164, -0.01468125,\n",
       "       -0.0080842 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ddcd2b",
   "metadata": {},
   "source": [
    "워드 벡터가 의미 벡터 공간상에 유의미하게 학습되었는지 확인하는 방법 중에, 단어를 하나 주고 그와 가장 유사한 단어와 그 유사도를 확인하는 방법이 있습니다. gensim을 사용하면 아래와 같이 해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "252b3ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('etc', 0.8324365615844727),\n",
       " ('outlaw', 0.8236098289489746),\n",
       " ('gypsy', 0.8139989972114563),\n",
       " ('daniel', 0.8124250173568726),\n",
       " ('burnt', 0.8031635284423828),\n",
       " ('pumbaa', 0.7961767315864563),\n",
       " ('management', 0.7901010513305664),\n",
       " ('tormented', 0.7886754870414734),\n",
       " ('ossessione', 0.7862859964370728),\n",
       " ('companions', 0.7843154072761536)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a2251",
   "metadata": {},
   "source": [
    " Google의 Word2Vec 모델을 가져와 적용해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b67d6435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa242048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "# word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97d8e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d59b341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fc11c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 4s 81ms/step - loss: 0.6899 - accuracy: 0.5385 - val_loss: 0.6822 - val_accuracy: 0.5715\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.6698 - accuracy: 0.5975 - val_loss: 0.6668 - val_accuracy: 0.5990\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 78ms/step - loss: 0.6055 - accuracy: 0.6749 - val_loss: 0.5706 - val_accuracy: 0.7048\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.4435 - accuracy: 0.8095 - val_loss: 0.3946 - val_accuracy: 0.8319\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 68ms/step - loss: 0.3126 - accuracy: 0.8728 - val_loss: 0.3481 - val_accuracy: 0.8464\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.2336 - accuracy: 0.9135 - val_loss: 0.3169 - val_accuracy: 0.8641\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.1734 - accuracy: 0.9453 - val_loss: 0.3172 - val_accuracy: 0.8665\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.1312 - accuracy: 0.9645 - val_loss: 0.3254 - val_accuracy: 0.8677\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.0972 - accuracy: 0.9777 - val_loss: 0.3323 - val_accuracy: 0.8701\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.0708 - accuracy: 0.9876 - val_loss: 0.3513 - val_accuracy: 0.8674\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 69ms/step - loss: 0.0505 - accuracy: 0.9936 - val_loss: 0.3565 - val_accuracy: 0.8678\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0356 - accuracy: 0.9974 - val_loss: 0.3731 - val_accuracy: 0.8717\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0254 - accuracy: 0.9983 - val_loss: 0.3894 - val_accuracy: 0.8688\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0193 - accuracy: 0.9988 - val_loss: 0.4059 - val_accuracy: 0.8703\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0144 - accuracy: 0.9993 - val_loss: 0.4206 - val_accuracy: 0.8687\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0111 - accuracy: 0.9995 - val_loss: 0.4366 - val_accuracy: 0.8683\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.4476 - val_accuracy: 0.8683\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.4619 - val_accuracy: 0.8685\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 70ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 0.4746 - val_accuracy: 0.8689\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.8687\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfb44bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5334 - accuracy: 0.8526\n",
      "[0.5333582162857056, 0.8525999784469604]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2a5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
